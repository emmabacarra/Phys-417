{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7f1be33f",
      "metadata": {
        "id": "7f1be33f"
      },
      "source": [
        "# Lab 6 Report:\n",
        "## Stock Prediction AI with Encoder-Decoder RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf02d733",
      "metadata": {
        "id": "bf02d733"
      },
      "source": [
        "### Name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9632cfb8",
      "metadata": {
        "id": "9632cfb8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a175cb4",
      "metadata": {
        "id": "7a175cb4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image # For displaying images in colab jupyter cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cf135d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "f6cf135d",
        "outputId": "82f88e93-77ec-4994-8479-578e618122ab"
      },
      "outputs": [],
      "source": [
        "Image('lab6_exercise.png', width = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "177bd488",
      "metadata": {
        "id": "177bd488"
      },
      "outputs": [],
      "source": [
        "# Seaborn plot styling\n",
        "sns.set(style = 'white', font_scale = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "855b4738",
      "metadata": {
        "id": "855b4738"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d234e0a0",
      "metadata": {
        "id": "d234e0a0"
      },
      "outputs": [],
      "source": [
        "# Load stock datasets\n",
        "# Pick one of three to train your model\n",
        "# Use 'closing price' column for training and testing\n",
        "\n",
        "# x = features/inputs, y = targets/outputs\n",
        "\n",
        "tesla = pd.read_csv('TSLA.csv')\n",
        "tesla_np = tesla.to_numpy()\n",
        "\n",
        "google = pd.read_csv('GOOGL.csv')\n",
        "google_np = google.to_numpy()\n",
        "\n",
        "dji = pd.read_csv('DJI.csv')\n",
        "dji_np = dji.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l6nuJBbT_dyt",
      "metadata": {
        "id": "l6nuJBbT_dyt"
      },
      "source": [
        "#### Building sequence function for next steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_p3j3sfZ1VXt",
      "metadata": {
        "id": "_p3j3sfZ1VXt"
      },
      "outputs": [],
      "source": [
        "def generate_input_output_seqs(y, encoder_inputseq_len, decoder_outputseq_len, stride = 1, num_features = 1):\n",
        "\n",
        "    L = y.shape[0] # Length of y\n",
        "\n",
        "    # Calculate how many input/target sequences there will be based on the parameters and stride\n",
        "    num_samples = (L - encoder_inputseq_len - decoder_outputseq_len) // stride + 1\n",
        "\n",
        "    # Numpy zeros arrray to contain the input/target sequences\n",
        "    # Note that they should be in (num_samples, seq_len, num_features/time step) format\n",
        "    train_input_seqs = np.zeros([num_samples, encoder_inputseq_len, num_features])\n",
        "    train_output_seqs = np.zeros([num_samples, decoder_outputseq_len, num_features])\n",
        "\n",
        "    # Iteratively fill in train_input_seqs and train_output_seqs\n",
        "    # See slide 17 of lab 7 to get an idea of how input_seqs and output_seqs look like\n",
        "    for ff in np.arange(num_features):\n",
        "\n",
        "        for ii in np.arange(num_samples):\n",
        "\n",
        "            start_x = stride * ii\n",
        "            end_x = start_x + encoder_inputseq_len\n",
        "            train_input_seqs[ii, :, ff] = y[start_x:end_x, ff]\n",
        "\n",
        "            start_y = stride * ii + encoder_inputseq_len\n",
        "            end_y = start_y + decoder_outputseq_len\n",
        "            train_output_seqs[ii, :, ff] = y[start_y:end_y, ff]\n",
        "\n",
        "    return train_input_seqs, train_output_seqs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WDXDEoqx_oLD",
      "metadata": {
        "id": "WDXDEoqx_oLD"
      },
      "source": [
        "#### Applying functions & preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0e21b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "bc0e21b7",
        "outputId": "ecd7c727-9a42-4ad9-cb14-ee0f984a6bfd"
      },
      "outputs": [],
      "source": [
        "# Normalize your data and select training dataset (all the days except for last 100 days)\n",
        "\n",
        "# ------ Selecting Google Stocks Dataset ------\n",
        "# based on the model's training with ggl_train, it will then\n",
        "#   use that information to predict the last 100 days, which\n",
        "#   can then be compared with the actual data from ggl_test\n",
        "\n",
        "# Using the closing price (column 4) as training sequence except for testing sequence (last 100 datapoints)\n",
        "ggl_train = torch.as_tensor(np.array(  google_np[:-100, 4]  ).astype('float32')).cuda()\n",
        "ggl_train = torch.unsqueeze(ggl_train, dim=1)\n",
        "ggl_test = torch.as_tensor(np.array(  google_np[-100:, 4]  ).astype('float32')).cuda()\n",
        "ggl_test = torch.unsqueeze(ggl_test, dim=1)\n",
        "\n",
        "\n",
        "# Define encoder/decoder sequence lengths and testing sequence length\n",
        "encoder_inputseq_len = 15                 # set to 5 in example\n",
        "decoder_outputseq_len = 10                # set to 2 in example\n",
        "testing_sequence_len = len(ggl_test)     # all except for last 100 days\n",
        "\n",
        "google_np.shape, ggl_train.shape, ggl_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8c97bd",
      "metadata": {
        "id": "bf8c97bd"
      },
      "outputs": [],
      "source": [
        "# Define your encoder input sequence length, decoder output sequence length and testing sequence length\n",
        "# Construct train_input_seqs and train_output_seqs according to\n",
        "# encoder input sequence length and decoder output sequence length similar to example task\n",
        "\n",
        "# Generate encoder input seqs and decoder output seqs\n",
        "train_input_seqs, train_output_seqs = generate_input_output_seqs(y = ggl_train.cpu(),\n",
        "                                                                 encoder_inputseq_len = encoder_inputseq_len,\n",
        "                                                                 decoder_outputseq_len = decoder_outputseq_len,\n",
        "                                                                 stride = 1,\n",
        "                                                                 num_features = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1a741f",
      "metadata": {
        "id": "2d1a741f"
      },
      "outputs": [],
      "source": [
        "# Make sure train_input_seqs and train_output_seqs have correct dimensions as expected\n",
        "# (sample size, sequence length, # of features / timestep)\n",
        "\n",
        "# shape will change based on stride parameter set in generate_input_output_seqs\n",
        "print(\"Encoder Training Inputs Shape: \", train_input_seqs.shape)\n",
        "print(\"Decoder Training Outputs Shape: \", train_output_seqs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfda0488",
      "metadata": {
        "id": "cfda0488"
      },
      "source": [
        "## Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53860c5c",
      "metadata": {
        "id": "53860c5c"
      },
      "outputs": [],
      "source": [
        "# building the enconder class\n",
        "class Encoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # Using LSTM (long short term memory) with batch_first = True\n",
        "        self.lstm = torch.nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                                  num_layers = num_layers,\n",
        "                                  batch_first = True)\n",
        "\n",
        "        # No need for FC layer since encoder only passes hidden states to Decoder\n",
        "\n",
        "    def forward(self, input_seq, hidden_state):\n",
        "        # forward propagate to LSTM\n",
        "        out, hidden = self.lstm(input_seq, hidden_state)\n",
        "        return out, hidden\n",
        "\n",
        "# building the decoder class\n",
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # Using LSTM for Decoder with batch_first = True\n",
        "        self.lstm = torch.nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                                  num_layers = num_layers,\n",
        "                                  batch_first = True)\n",
        "\n",
        "        # FC layer to convert hidden states to a single number\n",
        "        self.fc_decoder = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq, encoder_hidden_states):\n",
        "\n",
        "        # forward propagate to the LSTM\n",
        "        output, hidden = self.lstm(input_seq, encoder_hidden_states)\n",
        "\n",
        "        # pass output of lstm through FC layer and get a prediction\n",
        "        out = self.fc_decoder(output)\n",
        "        return out, hidden\n",
        "\n",
        "# Combine Encoder and Decoder classes into one class (model)\n",
        "class Encoder_Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, decoder_output_size, num_layers):\n",
        "\n",
        "        super(Encoder_Decoder, self).__init__()\n",
        "\n",
        "        # encoder-decoder layers\n",
        "        self.Encoder = Encoder(input_size = input_size, hidden_size = hidden_size,\n",
        "                               num_layers = num_layers)\n",
        "        self.Decoder = Decoder(input_size = input_size, hidden_size = hidden_size,\n",
        "                               output_size = decoder_output_size, num_layers = num_layers)\n",
        "        # RNN cell layer\n",
        "        self.rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size,\n",
        "                                num_layers = num_layers,\n",
        "                                nonlinearity = 'relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # encode input sequence\n",
        "        hidden = self.Encoder(x)\n",
        "\n",
        "        # passing encoder outputs through RNN\n",
        "        x = self.rnn(x, hidden)\n",
        "\n",
        "        # adding 1st dropout layer\n",
        "        x = torch.nn.functional.dropout(x, p=0.5)\n",
        "\n",
        "        # decode hidden state\n",
        "        x = self.Decoder(x, hidden)\n",
        "\n",
        "        # adding 2nd dropout layer\n",
        "        out = torch.nn.functional.dropout(x, p=0.5)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aac20f78",
      "metadata": {
        "id": "aac20f78"
      },
      "source": [
        "## Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7badc0c7",
      "metadata": {
        "id": "7badc0c7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1720)\n",
        "\n",
        "# Using input_size = 1 (# of features to be fed to RNN per timestep)\n",
        "# Using decoder_output_size = 1 (# of features to be output by Decoder RNN per timestep)\n",
        "Encoder_Decoder_RNN = Encoder_Decoder(input_size = 1, hidden_size = 15,\n",
        "                                      decoder_output_size = 1, num_layers = 1)\n",
        "\n",
        "# Define learning rate + epochs\n",
        "learning_rate = 10\n",
        "epochs = 90\n",
        "\n",
        "# Define batch size and num_features/timestep (this is simply the last dimension of train_output_seqs)\n",
        "batchsize = 800\n",
        "num_features = train_output_seqs.shape[2]\n",
        "\n",
        "# Define loss function/optimizer\n",
        "loss_func = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(Encoder_Decoder_RNN.parameters(), lr=learning_rate)\n",
        "\n",
        "# Model should take the hidden state and output from the encoder, then\n",
        "#   forward pass it into the decoder, which takes those values and uses\n",
        "#   them to output a final prediction\n",
        "Encoder_Decoder_RNN.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c403ae44",
      "metadata": {
        "id": "c403ae44"
      },
      "source": [
        "## Identify Tracked Values & Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb3ffcc",
      "metadata": {
        "id": "9eb3ffcc"
      },
      "outputs": [],
      "source": [
        "# Empty Python list to keep track of training loss\n",
        "train_loss_list = []\n",
        "\n",
        "\n",
        "# Convert training dataset into torch tensors\n",
        "train_input_seqs = torch.from_numpy(train_input_seqs).float().cuda()\n",
        "train_output_seqs = torch.from_numpy(train_output_seqs).float().cuda()\n",
        "\n",
        "# Split the training data into mini-batches\n",
        "# Skipping the last mini-batch since its size can be smaller than the set batchsize\n",
        "train_batches_features = torch.split(train_input_seqs, batchsize)[:-1]\n",
        "train_batches_targets = torch.split(train_output_seqs, batchsize)[:-1]\n",
        "\n",
        "# Compute total number of mini-batches in training data\n",
        "batch_split_num = len(train_batches_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ed7297",
      "metadata": {
        "id": "50ed7297",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import tqdm # Use \"for epoch in tqdm.trange(epochs):\" to see the progress bar\n",
        "\n",
        "for epoch in tqdm.trange(epochs): # For each epoch\n",
        "\n",
        "    for k in range(batch_split_num): # For each mini_batch\n",
        "\n",
        "        # initialize hidden states to Encoder\n",
        "        hidden_state = None\n",
        "\n",
        "        # initialize empty torch tensor array to store decoder output sequence\n",
        "        decoder_output_seq = torch.zeros(batchsize, decoder_outputseq_len, num_features).cuda()\n",
        "\n",
        "        # empty gradient buffer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Feed k-th mini-batch for encoder input sequences to encoder with hidden state\n",
        "        encoder_output, encoder_hidden = Encoder_Decoder_RNN.Encoder(train_batches_features[k], hidden_state)\n",
        "\n",
        "        # Re-define the resulting encoder hidden states as input hidden states to decoder\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # Initial input to decoder is last timestep feature from the encoder input sequence\n",
        "        decoder_input = train_batches_features[k][:, -1, :]\n",
        "        # The extracted feature is 2D so need to add additional 3rd dimension\n",
        "        # to conform to (sample size, seq_len, # of features)\n",
        "        decoder_input = torch.unsqueeze(decoder_input, 2)\n",
        "\n",
        "        # Populating the decoder output sequence\n",
        "        for t in range(decoder_outputseq_len): # for each timestep in output sequence\n",
        "\n",
        "            # Feed in the decoder_input and decoder_hidden to Decoder, get new output and hidden states\n",
        "            decoder_output, decoder_hidden = Encoder_Decoder_RNN.Decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "            # Populate the corresponding timestep in decoder output sequence\n",
        "            decoder_output_seq[:, t, :] = torch.squeeze(decoder_output, 2)\n",
        "\n",
        "            # Using teacher forcing so using the groundtruth training target as the next input\n",
        "            decoder_input = train_batches_targets[k][:, t, :]\n",
        "\n",
        "            # The extracted feature is 2D so need to add additional 3rd dimension\n",
        "            # to conform to (sample size, seq_len, # of features)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 2)\n",
        "\n",
        "        # Compare the predicted decoder output sequence aginast the target sequence to compute the MSE loss\n",
        "        loss = loss_func(torch.squeeze(decoder_output_seq), torch.squeeze(train_batches_targets[k]))\n",
        "\n",
        "        # Save the loss\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the RNN\n",
        "        optimizer.step()\n",
        "\n",
        "    #print(\"Averaged Training Loss for Epoch \", epoch,\": \", np.mean(train_loss_list[-batch_split_num:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b49cc5",
      "metadata": {
        "id": "e1b49cc5"
      },
      "source": [
        "## Visualize & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72efa14",
      "metadata": {
        "id": "c72efa14"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (9, 5))\n",
        "\n",
        "plt.plot(np.convolve(train_loss_list, np.ones(100), 'valid') / 100,\n",
        "         linewidth = 3, label = 'Rolling Averaged Training Loss')\n",
        "plt.ylabel(\"training loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.legend()\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ac4eceb",
      "metadata": {
        "id": "2ac4eceb"
      },
      "source": [
        "### Generate signal predictions for testing sequence with trained Encoder-Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00988cea",
      "metadata": {
        "id": "00988cea",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# USE TEACHER FORCING METHOD WHEN GENERATING OUTPUTS FROM DECODER\n",
        "# See slide 42 of Lab 5 or Lab 5 part 2 video to recap the concept of teacher forcing method\n",
        "# When generating decoder outputs, make sure each input to decoder at timestep t has the shape (1,1,1)\n",
        "# i.e., num_samples = 1, sequence_len = 1, num_features = 1\n",
        "\n",
        "# ---> IGNORE BELOW, test sequence is already a tensor:\n",
        "# Convert test sequence to tensor (test_input_seq in example)\n",
        "# ggl_test = torch.from_numpy(ggl_test).float()  # no .cuda() bc it was applied earlier(?)\n",
        "\n",
        "# initialize empty torch tensor array to store decoder output sequence\n",
        "# This should be the same size as the test sequence\n",
        "decoder_output_seq = torch.zeros(testing_sequence_len, num_features)\n",
        "\n",
        "# First n-datapoints in decoder output sequence = First n-datapoints in ground truth test sequence\n",
        "# n = encoder_input_seq_len\n",
        "decoder_output_seq[:encoder_inputseq_len] = ggl_test[:encoder_inputseq_len]\n",
        "\n",
        "# Initialize index for prediction\n",
        "pred_start_ind = 0\n",
        "\n",
        "# Activate no_grad() since we aren't performing backprop\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Loop continues until the RNN prediction reaches the end of the testing sequence length\n",
        "    while pred_start_ind + encoder_inputseq_len + decoder_outputseq_len < testing_sequence_len:\n",
        "\n",
        "        # initialize hidden state for encoder\n",
        "        hidden_state = None\n",
        "\n",
        "        # Define the input to encoder\n",
        "        input_test_seq = decoder_output_seq[pred_start_ind:pred_start_ind + encoder_inputseq_len]\n",
        "        # Add dimension to first dimension to keep the input (sample_size, seq_len, # of features/timestep)\n",
        "        input_test_seq = torch.unsqueeze(input_test_seq, 0)\n",
        "\n",
        "        # Feed the input to encoder and set resulting hidden states as input hidden states to decoder\n",
        "        encoder_output, encoder_hidden = Encoder_Decoder_RNN.Encoder(input_test_seq.cuda(), hidden_state)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # Initial input to decoder is last timestep feature from the encoder input sequence\n",
        "        decoder_input = input_test_seq[:, -1, :]\n",
        "        # Add dimension to keep the input (sample_size, seq_len, # of features/timestep)\n",
        "        decoder_input = torch.unsqueeze(decoder_input, 2)\n",
        "\n",
        "        # Populate decoder output sequence\n",
        "        for t in range(decoder_outputseq_len):\n",
        "\n",
        "            # Generate new output for timestep t\n",
        "            decoder_output, decoder_hidden = Encoder_Decoder_RNN.Decoder(decoder_input.cuda(), decoder_hidden)\n",
        "            # Populate the corresponding timestep in decoder output sequence\n",
        "            decoder_output_seq[pred_start_ind + encoder_inputseq_len + t] = torch.squeeze(decoder_output)\n",
        "            # Use the output of the decoder as new input for the next timestep\n",
        "            decoder_input = decoder_output\n",
        "\n",
        "        # Update pred_start_ind\n",
        "        pred_start_ind += decoder_outputseq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbccae5",
      "metadata": {
        "id": "fdbccae5"
      },
      "outputs": [],
      "source": [
        "# Visualize predicted stock sequence vs the ground truth (aka the test sequence of last 100 datapoints)\n",
        "\n",
        "plt.figure(figsize = (10, 5))\n",
        "\n",
        "plt.plot(ggl_test.cpu(), linewidth = 3, label = 'GroundTruth')\n",
        "plt.plot(decoder_output_seq, linewidth = 3, label = 'RNN Predicted')\n",
        "plt.title('RNN Predicted vs GroundTruth')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "\n",
        "\n",
        "# Compute the MSE error between test_input_seq and decoder_output_seq and print the value as Test MSE Error\n",
        "\n",
        "mse_error = mean_squared_error(ggl_test.cpu(), decoder_output_seq)\n",
        "print(f'Test MSE Error: {mse_error}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17UgoNq4no1v",
      "metadata": {
        "id": "17UgoNq4no1v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
