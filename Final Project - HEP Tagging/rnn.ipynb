{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ebaca\\\\Desktop\\\\Phys 417\\\\Final Project - HEP Tagging'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries & making torch.device object for GPU\n",
    "\n",
    "# neural network packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from torch import Tensor\n",
    "# from torch.nn import Transformer\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# data packages\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "# import sklearn.preprocessing as prep\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# visual packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "# Create a torch.device object to tell pytorch where to store your tensors: cpu or gpu\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0, 0, 0, 0): ['Gluon', 3942],\n",
       " (0, 1, 0, 0, 0): ['Light Quark', 3835],\n",
       " (0, 0, 1, 0, 0): ['W Boson', 4150],\n",
       " (0, 0, 0, 1, 0): ['Z Boson', 4053],\n",
       " (0, 0, 0, 0, 1): ['Top Quark', 4020]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "onehots = {\n",
    "    (1, 0, 0, 0, 0): ['Gluon', 0],\n",
    "    (0, 1, 0, 0, 0): ['Light Quark', 0],\n",
    "    (0, 0, 1, 0, 0): ['W Boson', 0],\n",
    "    (0, 0, 0, 1, 0): ['Z Boson', 0],\n",
    "    (0, 0, 0, 0, 1): ['Top Quark', 0]\n",
    "}\n",
    "# print(list(onehots.values()))\n",
    "\n",
    "files = shuffle([os.path.join('../../PHYS417_Project/data/'+ f) for f in os.listdir('../../PHYS417_Project/data')])\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    # with np.load('../../PHYS417_Project/data/' + f) as data_load:\n",
    "    with np.load(f) as data_load:\n",
    "        y = data_load['y']\n",
    "\n",
    "        if tuple(y) in onehots:\n",
    "            onehots[tuple(y)][1] += 1\n",
    "\n",
    "display(onehots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 70% of files: 14000 \n",
      "Last 30% of files: 6000\n",
      "14000 Training Files  + 6000 Testing Files  =  20000 Total Files\n",
      "\n",
      "First 5 training files: ['../../PHYS417_Project/data/event_0210843.npz', '../../PHYS417_Project/data/event_0853950.npz', '../../PHYS417_Project/data/event_0150345.npz', '../../PHYS417_Project/data/event_0063113.npz', '../../PHYS417_Project/data/event_0629457.npz'] \n",
      "First 5 testing files: ['../../PHYS417_Project/data/event_0572190.npz', '../../PHYS417_Project/data/event_0383752.npz', '../../PHYS417_Project/data/event_0119255.npz', '../../PHYS417_Project/data/event_0786239.npz', '../../PHYS417_Project/data/event_0612971.npz']\n",
      "\n",
      "TrSet (event 0): torch.Size([31, 5]) \n",
      "tensor([[0.7103, -0.0000, 0.0000, 0.7085, 0.0018]]) \n",
      "Onehot vector: tensor([0., 0., 0., 1., 0.])\n",
      "\n",
      "\n",
      " --------------------------------------- [Batch 0] --------------------------------------- \n",
      "\n",
      "Input shape: torch.Size([13, 97, 5]), Label shape: torch.Size([13, 5])\n",
      "\n",
      "--Event 0.0-- \n",
      "[[ 0.1969187  -0.          0.          0.19086745  0.04586895]] \n",
      "[[0. 0. 0. 0. 0.]], \n",
      "Tag: [0. 0. 0. 1. 0.]\n",
      "\n",
      "--Event 0.1-- \n",
      "[[ 0.10992359 -0.          0.          0.10886057  0.13993742]] \n",
      "[[0. 0. 0. 0. 0.]], \n",
      "Tag: [1. 0. 0. 0. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:26<03:58, 26.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4991\n",
      "Inputs: torch.Size([12, 127, 5])  \n",
      "Onehot: [0. 0. 0. 1. 0.]  ArgMax Index: [3]\n",
      "Outputs: [-1.641184  -1.2442324 -1.4228164 -1.3074638 -1.4104962]\n",
      "Probabilities: [0.15656933 0.23286304 0.19477917 0.21859467 0.19719374]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:52<03:31, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.4954\n",
      "Inputs: torch.Size([12, 102, 5])  \n",
      "Onehot: [0. 1. 0. 0. 0.]  ArgMax Index: [1]\n",
      "Outputs: [-1.5564519 -1.1370878 -1.246305  -1.3278059 -1.7185264]\n",
      "Probabilities: [0.16689213 0.25384194 0.22757836 0.20976622 0.14192137]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:18<03:02, 26.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4876\n",
      "Inputs: torch.Size([12, 96, 5])  \n",
      "Onehot: [0. 0. 1. 0. 0.]  ArgMax Index: [2]\n",
      "Outputs: [-2.1131055  -1.0156972  -0.84513044 -1.2548186  -1.8590342 ]\n",
      "Probabilities: [0.08929832 0.2675726  0.31733492 0.21066509 0.11512908]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:44<02:35, 25.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4529\n",
      "Inputs: torch.Size([12, 95, 5])  \n",
      "Onehot: [1. 0. 0. 0. 0.]  ArgMax Index: [0]\n",
      "Outputs: [-0.28520775 -2.9130874  -3.5405474  -3.3613315  -0.50127983]\n",
      "Probabilities: [0.5095245  0.0368037  0.0196512  0.02350832 0.4105123 ]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:09<02:08, 25.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.4512\n",
      "Inputs: torch.Size([12, 81, 5])  \n",
      "Onehot: [0. 1. 0. 0. 0.]  ArgMax Index: [1]\n",
      "Outputs: [-1.3457868 -1.38286   -1.0999743 -1.1412121 -2.3141077]\n",
      "Probabilities: [0.20622857 0.19872302 0.2636962  0.2530431  0.07830913]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:34<01:42, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.3255\n",
      "Inputs: torch.Size([12, 88, 5])  \n",
      "Onehot: [0. 1. 0. 0. 0.]  ArgMax Index: [1]\n",
      "Outputs: [-0.23390654 -1.8668593  -2.4021192  -2.1355963  -1.6707519 ]\n",
      "Probabilities: [0.58937025 0.11513459 0.06741328 0.08800247 0.14007936]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:00<01:16, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.2908\n",
      "Inputs: torch.Size([12, 97, 5])  \n",
      "Onehot: [0. 0. 0. 0. 1.]  ArgMax Index: [4]\n",
      "Outputs: [-2.3323786 -2.1303637 -5.2832727 -3.8702602  1.2144938]\n",
      "Probabilities: [0.0268849  0.03290352 0.00140589 0.00577584 0.93302983]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [03:25<00:50, 25.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3519\n",
      "Inputs: torch.Size([12, 57, 5])  \n",
      "Onehot: [0. 1. 0. 0. 0.]  ArgMax Index: [1]\n",
      "Outputs: [-3.1431987   0.09539345 -1.1318198  -1.5311161  -4.1771116 ]\n",
      "Probabilities: [0.02541925 0.6481349  0.18997368 0.12743281 0.00903941]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:50<00:25, 25.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3667\n",
      "Inputs: torch.Size([12, 84, 5])  \n",
      "Onehot: [0. 0. 1. 0. 0.]  ArgMax Index: [2]\n",
      "Outputs: [-0.6090559  -0.50906336 -1.752686   -2.2136772  -3.8611157 ]\n",
      "Probabilities: [0.37544826 0.4149314  0.11964039 0.0754522  0.01452775]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:16<00:00, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3045\n",
      "Inputs: torch.Size([12, 98, 5])  \n",
      "Onehot: [0. 1. 0. 0. 0.]  ArgMax Index: [1]\n",
      "Outputs: [-3.1691008  1.4804101 -2.38379   -2.7353785 -4.8923864]\n",
      "Probabilities: [0.00913673 0.95509696 0.02003765 0.01409787 0.00163071]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your model architecture\n",
    "class JetClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(JetClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# custom PyTorch dataset (for DataLoader)\n",
    "class JetDataset(Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        with np.load(file_path) as data_load:\n",
    "            x_load = torch.tensor(data_load['x'], dtype=torch.float32)\n",
    "            y_load = torch.tensor(data_load['y'], dtype=torch.float32)\n",
    "        return x_load, y_load\n",
    "\n",
    "# the collate function lets the model handle variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    # sorting batch in descending order of # of constituents\n",
    "    # batch.sort(key=lambda x: x[0].size(0), reverse=True)   # option to sort by sequence length\n",
    "    inputs, labels = zip(*batch)\n",
    "    # adding padding to the sequences\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    # labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)  # Ensure labels are stacked without padding\n",
    "    return inputs_padded, labels\n",
    "\n",
    "# function to extract numpy arrays from tensors\n",
    "extractor = lambda x: x.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "'''Extracting Files ----------------------------------------------------------'''\n",
    "\n",
    "print(f'First 70% of files: {len(files[:int(0.7*len(files))])} \\nLast 30% of files: {len(files[int(0.7*len(files)):])}')\n",
    "\n",
    "\n",
    "\n",
    "'''Splitting Files ----------------------------------------------------------'''\n",
    "\n",
    "# splitting into training/testing sets\n",
    "train_files = files[:int(0.7*len(files))]\n",
    "test_files = files[int(0.7*len(files)):]\n",
    "\n",
    "print(f\"{len(train_files)} Training Files  + {len(test_files)} Testing Files  =  {len(files)} Total Files\\n\")\n",
    "print(f'First 5 training files: {train_files[:5]} \\nFirst 5 testing files: {test_files[:5]}\\n')\n",
    "\n",
    "\n",
    "\n",
    "'''Converting to Dataset Objects --------------------------------------------------------'''\n",
    "\n",
    "train_dataset = JetDataset(train_files)\n",
    "test_dataset = JetDataset(test_files)\n",
    "\n",
    "# train_dataset[event n][input/label][constituent n, property n]\n",
    "print(f'TrSet (event 0): {train_dataset[0][0].shape} \\n{train_dataset[0][0][:1]} \\nOnehot vector: {train_dataset[0][1]}\\n')\n",
    "# print(f'TeSet First const. (event 0): \\n{test_dataset[0][0][:1]} \\nOnehot vector: {test_dataset[0][1]}\\n')\n",
    "\n",
    "\n",
    "\n",
    "'''Creating DataLoaders/Applying Collate Fn (Padding) --------------------------------------------------------'''\n",
    "\n",
    "class_weights = [1 / count for count in [value[1] for value in onehots.values()]]\n",
    "weights = [\n",
    "    class_weights[torch.argmax(tag).item()] \n",
    "        for tag in [train_dataset[i][1] \n",
    "                for i in range(len(train_dataset))]\n",
    "]\n",
    "sampler = WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
    "\n",
    "# make datasets into DataLoader objects and apply collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=13, shuffle=False, collate_fn=collate_fn, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=13, shuffle=False, collate_fn=collate_fn, sampler=sampler)\n",
    "\n",
    "# inspecting how padding went in collate_fn\n",
    "# loader[input or label][batch n][event e][constituent n, property n]\n",
    "n=0\n",
    "for nbatch_x, nbatch_y in train_loader: # loops through n batches or loader[input/label][batch n]\n",
    "    # inputs = array containing each events' data['x'] in the batch\n",
    "    # labels = array containing each events' data['y'] in the batch\n",
    "    print(f'\\n --------------------------------------- [Batch {n}] --------------------------------------- \\n')\n",
    "    print(f'Input shape: {nbatch_x.shape}, Label shape: {nbatch_y.shape}\\n') # general shape of the batch\n",
    "\n",
    "    e=0\n",
    "    # printing first 5 events in the batch\n",
    "    for (properties, tag) in zip(nbatch_x[:2], nbatch_y[:2]):\n",
    "        # printing the first 5 constituents/properties\n",
    "        print(f'--Event {n}.{e}--',\n",
    "              f'\\n{extractor(properties[:1])} \\n{extractor(properties[-1:])}, \\nTag: {extractor(tag)}\\n')\n",
    "        e+=1\n",
    "    \n",
    "    # to stop after some number of events\n",
    "    n+=1\n",
    "    if n == 1: \n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Initializing Model & Hyperparameters ----------------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 5  # Number of features for each constituent\n",
    "hidden_size = 1280\n",
    "num_layers = 1\n",
    "num_classes = 5  # Number of categories for jet classification\n",
    "\n",
    "model = JetClassifier(input_size, hidden_size, num_layers, num_classes).to(DEVICE)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss().to(DEVICE)  # Binary Cross Entropy Loss for multi-label classification\n",
    "# criterion = nn.CrossEntropyLoss().to(DEVICE)  # includes softmax layer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "Training -------------------------------------------------------------------\n",
    "'''\n",
    "# [batch size][max sequence length][input size/number of features]\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    for events, tags in train_loader:\n",
    "        events, onehots = events.to(DEVICE), tags.to(DEVICE)\n",
    "        # tags = torch.argmax(onehots, dim=1) # Convert one-hot encoded labels to single integer labels\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(events)\n",
    "\n",
    "        # loss = criterion(outputs, tags)\n",
    "        loss = criterion(outputs, onehots)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Inputs: {events.shape}  \\nOnehot: {extractor(onehots[:1][0])}  ArgMax Index: {extractor(onehots[:1].argmax(dim=1))}')\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    probabilities = softmax(outputs)\n",
    "    print(f'Outputs: {extractor(outputs[:1][0])}')\n",
    "    print(f'Probabilities: {extractor(probabilities[:1][0])}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ebaca\\anaconda3\\envs\\Phys417\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ebaca\\anaconda3\\envs\\Phys417\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ebaca\\anaconda3\\envs\\Phys417\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ebaca\\anaconda3\\envs\\Phys417\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mJetDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 30\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(file_path) \u001b[38;5;28;01mas\u001b[39;00m data_load:\n\u001b[0;32m     32\u001b[0m         x_load \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data_load[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Evaluation -------------------------------------------------------------------\n",
    "\n",
    "[batch size][max sequence length][input size/number of features]\n",
    "'''\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in test_loader:\n",
    "            labels = torch.argmax(labels, dim=1).to(DEVICE)\n",
    "            outputs = model(sequences.to(DEVICE))\n",
    "            predicted = torch.argmax(outputs, dim=1).to(DEVICE)\n",
    "\n",
    "            print(predicted)\n",
    "            print(labels, '\\n')\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phys417",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
