{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ebaca\\\\Desktop\\\\Phys 417\\\\Final Project - HEP Tagging'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries & making torch.device object for GPU\n",
    "\n",
    "# neural network packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pack_sequence, pad_sequence\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# data packages\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import fndict as fd\n",
    "\n",
    "# visual packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import warnings\n",
    "import pprint as pp\n",
    "\n",
    "# Create a torch.device object to tell pytorch where to store your tensors: cpu or gpu\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 5) [0 0 0 1 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = shuffle([f for f in os.listdir('../../PHYS417_Project/data')])\n",
    "\n",
    "test_index = 0\n",
    "data = []\n",
    "\n",
    "for i, f in enumerate(files[:100]):\n",
    "    with np.load('../../PHYS417_Project/data/' + f) as data_load:\n",
    "        x_load = data_load['x']\n",
    "        y_load = data_load['y']\n",
    "        data.append([x_load, y_load])\n",
    "\n",
    "        if i == test_index:\n",
    "            print(x_load.shape, y_load, '\\n')\n",
    "\n",
    "data = np.array(data, dtype=object)\n",
    "\n",
    "'''\n",
    "the dataset then contains these dimensions:\n",
    "data[event index][event information][event constituents]\n",
    "\n",
    "event index: \n",
    "data[i] = [event1, event2, ..., eventn]\n",
    "- index for a specific event in a set number of sampled events\n",
    "- number of samples stays the same throughout a training session\n",
    "\n",
    "event information:\n",
    "data[i][0] = [[constituent1], [constituent2], ..., [constituentn]]\n",
    "data[i][1] = [one-hot encoded jet tag for 5 categories]\n",
    "- 0 for a variable number of constituents and their 5 properties (data['x'] of one event file)\n",
    "- 1 for the jet tag (represented as a one-hot encoded vector) (data['y'] of one event file)\n",
    "- always either 0 or 1, doesn't change ever\n",
    "\n",
    "event constituents: \n",
    "data[i][0][constituentn] = [momentum, eta, phi, energy, distance]\n",
    "- varying number n for each event[i][0][n]\n",
    "- each represents a row of the nx5 matrix in event[i][0]\n",
    "\n",
    "'''\n",
    "\n",
    "class ParticleDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        \n",
    "        # Convert x to a list of tensors\n",
    "        x_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in x]\n",
    "        \n",
    "        # Pack the sequence of tensors\n",
    "        packed_x = pack_sequence(x_tensors, enforce_sorted=False)\n",
    "        \n",
    "        return packed_x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final shape of data_array: {data.shape}\", f\"\\nShape X (features) {data[:, 0].shape}\", f\"\\nShape Y (targets) {data[:, 1].shape}\\n\")\n",
    "\n",
    "print(data[test_index, 0].shape, data[test_index, 1]) # [data element index][0 for data_load['x'], 1 for data_load['y']][constituent index]\n",
    "\n",
    "# class ParticleDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         # Return a tuple containing features (x) and targets (y)\n",
    "#         return self.data[idx][0], self.data[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3512 Training Files  + 1506 Testing Files  =  5018 Total Files\n",
      "\n",
      "Inputs: torch.Size([13, 105, 5]), Labels: torch.Size([13, 5]) \n",
      "\n",
      "Epoch [1/10], Loss: 1.0627\n",
      "Inputs: torch.Size([2, 53, 5])  \n",
      "Onehot: [0. 0. 0. 0. 1.]  ArgMax Index: 4\n",
      "Probabilities: [0.4329131  0.02739702 0.01431549 0.03300458 0.4923699 ]\n",
      "\n",
      "\n",
      "Epoch [2/10], Loss: 1.6374\n",
      "Inputs: torch.Size([2, 59, 5])  \n",
      "Onehot: [0. 0. 1. 0. 0.]  ArgMax Index: 2\n",
      "Probabilities: [0.21412326 0.19273259 0.20080373 0.18838477 0.20395571]\n",
      "\n",
      "\n",
      "Epoch [3/10], Loss: 1.6131\n",
      "Inputs: torch.Size([2, 59, 5])  \n",
      "Onehot: [0. 0. 0. 0. 1.]  ArgMax Index: 4\n",
      "Probabilities: [0.20148997 0.18933281 0.21059448 0.20099041 0.19759224]\n",
      "\n",
      "\n",
      "Epoch [4/10], Loss: 1.5641\n",
      "Inputs: torch.Size([2, 89, 5])  \n",
      "Onehot: [1. 0. 0. 0. 0.]  ArgMax Index: 0\n",
      "Probabilities: [0.210441   0.17466551 0.19117518 0.20812348 0.21559484]\n",
      "\n",
      "\n",
      "Epoch [5/10], Loss: 1.5559\n",
      "Inputs: torch.Size([2, 86, 5])  \n",
      "Onehot: [1. 0. 0. 0. 0.]  ArgMax Index: 0\n",
      "Probabilities: [0.20733067 0.18848772 0.19842994 0.19095495 0.2147967 ]\n",
      "\n",
      "\n",
      "Epoch [6/10], Loss: 1.5732\n",
      "Inputs: torch.Size([2, 59, 5])  \n",
      "Onehot: [0. 0. 0. 0. 1.]  ArgMax Index: 4\n",
      "Probabilities: [0.19932824 0.18193707 0.21824037 0.20362185 0.19687238]\n",
      "\n",
      "\n",
      "Epoch [7/10], Loss: 1.6441\n",
      "Inputs: torch.Size([2, 39, 5])  \n",
      "Onehot: [0. 0. 0. 1. 0.]  ArgMax Index: 3\n",
      "Probabilities: [0.21502855 0.19237213 0.19214262 0.19316787 0.20728888]\n",
      "\n",
      "\n",
      "Epoch [8/10], Loss: 1.6311\n",
      "Inputs: torch.Size([2, 80, 5])  \n",
      "Onehot: [0. 0. 0. 0. 1.]  ArgMax Index: 4\n",
      "Probabilities: [0.21364714 0.19690795 0.19363713 0.20128404 0.19452375]\n",
      "\n",
      "\n",
      "Epoch [9/10], Loss: 1.5769\n",
      "Inputs: torch.Size([2, 32, 5])  \n",
      "Onehot: [0. 0. 0. 1. 0.]  ArgMax Index: 3\n",
      "Probabilities: [0.21296138 0.19360761 0.19609843 0.2065999  0.19073264]\n",
      "\n",
      "\n",
      "Epoch [10/10], Loss: 1.6223\n",
      "Inputs: torch.Size([2, 81, 5])  \n",
      "Onehot: [1. 0. 0. 0. 0.]  ArgMax Index: 0\n",
      "Probabilities: [0.20873764 0.19656901 0.18663906 0.2019215  0.20613281]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your model architecture\n",
    "class JetClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(JetClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# custom PyTorch dataset (for DataLoader)\n",
    "class JetDataset(Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        with np.load(file_path) as data_load:\n",
    "            x_load = torch.tensor(data_load['x'], dtype=torch.float32)\n",
    "            y_load = torch.tensor(data_load['y'], dtype=torch.float32)\n",
    "        return x_load, y_load\n",
    "\n",
    "# the collate function lets the model handle variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    # sorting batch in descending order of # of constituents\n",
    "    batch.sort(key=lambda x: x[0].size(0), reverse=True)\n",
    "    inputs, labels = zip(*batch)\n",
    "    # adding padding to the sequences\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "    return inputs_padded, labels_padded\n",
    "\n",
    "# function to extract numpy arrays from tensors\n",
    "extractor = lambda x: x.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "files = shuffle([os.path.join('../../PHYS417_Project/data', f) for f in os.listdir('../../PHYS417_Project/data')])\n",
    "\n",
    "# splitting into training/testing sets\n",
    "train_files = files[:int(0.7*len(files))]\n",
    "test_files = files[int(0.7*len(files)):]\n",
    "\n",
    "print(f\"{len(train_files)} Training Files  + {len(test_files)} Testing Files  =  {len(files)} Total Files\\n\")\n",
    "\n",
    "# make datasets into DataLoader objects and apply collate_fn\n",
    "train_dataset = JetDataset(train_files)\n",
    "test_dataset = JetDataset(test_files)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=13, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=13, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    print(f'Inputs: {inputs.shape}, Labels: {labels.shape} \\n')\n",
    "    break\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 5  # Number of features for each constituent\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 5  # Number of categories for jet classification\n",
    "\n",
    "model = JetClassifier(input_size, hidden_size, num_layers, num_classes).to(DEVICE)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss().to(DEVICE)  # Binary Cross Entropy Loss for multi-label classification\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)  # includes softmax layer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "''' \n",
    "Training -------------------------------------------------------------------\n",
    "\n",
    "[batch size][max sequence length][input size/number of features]\n",
    "'''\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for events, tags in train_loader:\n",
    "        events, onehots = events.to(DEVICE), tags.to(DEVICE)\n",
    "        tags = torch.argmax(onehots, dim=1) # Convert one-hot encoded labels to single integer labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(events)\n",
    "        loss = criterion(outputs, tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Inputs: {events.shape}  \\nOnehot: {extractor(onehots[:1][0])}  ArgMax Index: {tags[:1].item()}')\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    probabilities = softmax(outputs)\n",
    "    print(f'Probabilities: {extractor(probabilities[:1][0])}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20841897 0.19631071 0.18718179 0.20186096 0.20622754]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840862 0.19631496 0.18718563 0.20186542 0.20622537]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840481 0.19631924 0.18719195 0.20186411 0.20621991]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20839083 0.19632146 0.18720761 0.20186904 0.20621099]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20845902 0.19628274 0.18713099 0.20186083 0.20626639]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.208439   0.19630907 0.1871508  0.20185438 0.20624666]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840639 0.19632132 0.18718901 0.20186228 0.20622107]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20845185 0.19628565 0.18713994 0.20186211 0.20626038]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842324 0.19631054 0.18717799 0.20185895 0.20622931]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845099 0.19629812 0.18713385 0.2018569  0.20626006]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20846844 0.19629166 0.18711674 0.2018519  0.20627128]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845783 0.19630545 0.1871293  0.20184836 0.20625904]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084272  0.1963007  0.18716304 0.20186566 0.20624334]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084114  0.19631413 0.1871783  0.2018655  0.2062307 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20844424 0.19629882 0.18714322 0.2018589  0.2062548 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842956 0.19630703 0.18716024 0.20186095 0.20624223]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20841867 0.19631773 0.18718126 0.20185658 0.20622566]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20845258 0.19630955 0.18713932 0.20184736 0.20625123]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 3  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 1. 0.]  Probabilities: [0.20843963 0.19631428 0.18715774 0.20184828 0.20624003]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20844577 0.19629139 0.1871491  0.20186096 0.20625275]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 3  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 1. 0.]  Probabilities: [0.20838197 0.19633178 0.18721698 0.20186745 0.2062018 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845656 0.19631176 0.18713115 0.20184396 0.20625655]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20839678 0.19632606 0.18719846 0.20186399 0.20621467]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20843735 0.19629665 0.18716347 0.20186034 0.20624217]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20847009 0.1962872  0.18712027 0.20185272 0.20626977]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844032 0.19629517 0.18715514 0.20186129 0.2062481 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20838127 0.19633617 0.18721567 0.20186552 0.2062013 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840798 0.1963181  0.18718782 0.20186348 0.20622267]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20839477 0.19634436 0.18720134 0.20185392 0.20620564]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20840731 0.19632791 0.18718414 0.20185864 0.20622195]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842548 0.19632564 0.1871629  0.20185155 0.20623443]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845662 0.19631034 0.18713893 0.20184237 0.20625176]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20845306 0.19629751 0.18713072 0.20185597 0.2062628 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842658 0.19632682 0.18716596 0.20184909 0.20623158]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840487 0.19633391 0.18718813 0.2018557  0.20621735]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 1  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 1. 0. 0. 0.]  Probabilities: [0.20842303 0.19632538 0.18717784 0.20184949 0.20622422]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20839706 0.19632898 0.18720306 0.2018614  0.20620953]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084406  0.1963246  0.18715426 0.2018424  0.20623815]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845422 0.19630945 0.18714485 0.20184383 0.20624761]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20845571 0.19631653 0.18714264 0.20183875 0.20624632]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084347  0.19629696 0.18716596 0.20186098 0.20624143]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842986 0.1963049  0.18716991 0.20185927 0.20623614]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084166  0.19632442 0.18718222 0.20185402 0.20622273]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20847467 0.19629979 0.187115   0.20184138 0.20626915]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20841208 0.19630957 0.18718266 0.20186685 0.20622885]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842955 0.19632241 0.18716167 0.2018512  0.20623514]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20839208 0.19633567 0.18720824 0.20185967 0.2062044 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20843965 0.19631918 0.18715249 0.20184764 0.20624106]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20841055 0.19632475 0.18718313 0.20185824 0.20622331]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20841664 0.19631864 0.18718539 0.20185643 0.20622295]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084045  0.19631644 0.18719473 0.20186538 0.206219  ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084469  0.19632156 0.18715005 0.20184061 0.20624089]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20851552 0.19624873 0.187069   0.20185469 0.20631202]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20846404 0.1962828  0.18712237 0.2018591  0.20627162]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20837474 0.19633579 0.18722042 0.20186934 0.2061997 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084701  0.19631708 0.18712583 0.2018317  0.20625523]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842747 0.19632697 0.1871594  0.20184997 0.20623615]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20839116 0.19634096 0.1872075  0.20185715 0.20620322]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842935 0.19631778 0.18716183 0.20185341 0.2062376 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20839208 0.1963296  0.18720748 0.20186345 0.20620738]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 1  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 1. 0. 0. 0.]  Probabilities: [0.20842749 0.19630322 0.1871698  0.20186229 0.20623718]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20841475 0.19631913 0.18717661 0.20186009 0.20622945]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20846398 0.19630264 0.18712042 0.20184681 0.20626615]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 1  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 1. 0. 0. 0.]  Probabilities: [0.20842093 0.19631295 0.18717793 0.20185879 0.2062294 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20844488 0.19630845 0.18714634 0.201851   0.20624934]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20839547 0.19633943 0.18720475 0.2018555  0.20620488]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20849453 0.19627978 0.18710694 0.20184177 0.20627695]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084371  0.19632593 0.18715718 0.20184325 0.20623656]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840092 0.19633488 0.18719544 0.20185615 0.2062126 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844573 0.19631101 0.18714823 0.20184806 0.2062469 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842122 0.1963152  0.18717875 0.20185718 0.20622763]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20843565 0.19631314 0.18716517 0.20185038 0.20623568]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20839445 0.19633235 0.18720286 0.20186089 0.20620945]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084236  0.19630955 0.1871707  0.20186132 0.20623478]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084314  0.196298   0.1871721  0.20186132 0.20623714]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840834 0.19631451 0.18719217 0.20186378 0.2062212 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20843242 0.19630533 0.1871615  0.20185935 0.20624146]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844652 0.19631298 0.1871418  0.20184852 0.20625018]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20843747 0.19630934 0.18714923 0.20185587 0.20624807]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20845236 0.19630441 0.18714638 0.20184739 0.20624943]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844564 0.19629967 0.18715675 0.20185405 0.20624393]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084544  0.19630536 0.1871299  0.20184988 0.20626043]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20839801 0.19632316 0.18719496 0.20186579 0.20621808]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20846123 0.19630046 0.18712328 0.20185019 0.20626487]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084645  0.19631238 0.18713567 0.20183653 0.20625092]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20841639 0.1963231  0.18718424 0.20185465 0.20622167]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084832  0.19629295 0.1870976  0.20184393 0.20628233]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842588 0.19632612 0.18717329 0.2018481  0.20622656]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20843707 0.19631033 0.18716404 0.20185158 0.20623706]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20838034 0.19633998 0.18721993 0.20186254 0.20619716]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844495 0.19628751 0.1871528  0.20186289 0.20625184]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842743 0.19630726 0.18717165 0.20185925 0.20623443]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842928 0.19629683 0.1871698  0.20186463 0.20623945]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20842643 0.1963189  0.18716225 0.2018554  0.20623696]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20836118 0.19635354 0.1872366  0.20186481 0.20618387]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20846835 0.1962839  0.1871139  0.20185716 0.20627661]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844817 0.1963187  0.18714532 0.20184234 0.20624551]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20846845 0.19629705 0.18711771 0.20184754 0.20626925]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844501 0.1963125  0.18714505 0.20184885 0.20624852]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084323  0.19630885 0.1871594  0.20185784 0.20624164]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842364 0.1963059  0.18717337 0.20186268 0.20623435]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20842503 0.19632126 0.18716198 0.20185511 0.20623659]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 1  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 1. 0. 0. 0.]  Probabilities: [0.20839456 0.19633245 0.1872014  0.20186104 0.2062106 ]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20838141 0.19633685 0.18721746 0.20186464 0.20619963]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20843595 0.19632706 0.18716443 0.20184162 0.20623092]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840363 0.19632763 0.18718678 0.20186096 0.20622101]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20838143 0.1963383  0.18721807 0.2018632  0.20619899]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20843787 0.19631381 0.18715216 0.20185152 0.20624468]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.2084606  0.19630842 0.18713623 0.20184153 0.20625317]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.2084875  0.19629623 0.18709454 0.20184004 0.20628169]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20846976 0.19629878 0.18711439 0.20184651 0.20627056]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20844305 0.1963206  0.18714356 0.20184574 0.20624699]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20844224 0.19631484 0.18714695 0.2018491  0.20624682]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20836388 0.19635773 0.18723847 0.20185983 0.20618014]\n",
      "\n",
      "torch.Size([13, 5])\n",
      "Tag Index: 0  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [1. 0. 0. 0. 0.]  Probabilities: [0.20840463 0.19633545 0.18718976 0.20185453 0.20621553]\n",
      "\n",
      "torch.Size([11, 5])\n",
      "Tag Index: 4  Predicted Index: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Onehot: [0. 0. 0. 0. 1.]  Probabilities: [0.20844409 0.19630687 0.18715008 0.20185272 0.20624627]\n",
      "\n",
      "Test Accuracy: 0.2052\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Evaluation -------------------------------------------------------------------\n",
    "\n",
    "[batch size][max sequence length][input size/number of features]\n",
    "'''\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for events, onehots in data_loader:\n",
    "            events, onehots = events.to(device), onehots.to(device)\n",
    "            tags = torch.argmax(onehots, dim=1)  # Convert one-hot encoded labels to single integer labels\n",
    "\n",
    "            outputs = model(events)\n",
    "            loss = criterion(outputs, tags)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class by finding the index with the max probability\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            probabilities = softmax(outputs)\n",
    "            print(probabilities.shape)\n",
    "            predicted = torch.argmax(probabilities, dim=1)\n",
    "            total += tags.size(0)\n",
    "            correct += (predicted == tags).sum().item()\n",
    "\n",
    "            print(f'Tag Index: {tags[:1].item()}  Predicted Index: {predicted}')\n",
    "            print(f'Onehot: {extractor(onehots[:1][0])}  Probabilities: {extractor(probabilities[:1][0])}\\n')\n",
    "\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([13, 93, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 29 \n",
      "\n",
      "Inputs: torch.Size([13, 81, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 56 \n",
      "\n",
      "Inputs: torch.Size([13, 91, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 85 \n",
      "\n",
      "Inputs: torch.Size([13, 79, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 116 \n",
      "\n",
      "Inputs: torch.Size([13, 94, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 147 \n",
      "\n",
      "Inputs: torch.Size([13, 92, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 178 \n",
      "\n",
      "Inputs: torch.Size([13, 60, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 211 \n",
      "\n",
      "Inputs: torch.Size([13, 92, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 244 \n",
      "\n",
      "Inputs: torch.Size([13, 90, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 269 \n",
      "\n",
      "Inputs: torch.Size([13, 109, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 302 \n",
      "\n",
      "Inputs: torch.Size([13, 64, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 327 \n",
      "\n",
      "Inputs: torch.Size([13, 85, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 356 \n",
      "\n",
      "Inputs: torch.Size([13, 112, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 383 \n",
      "\n",
      "Inputs: torch.Size([13, 86, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 414 \n",
      "\n",
      "Inputs: torch.Size([13, 80, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 437 \n",
      "\n",
      "Inputs: torch.Size([13, 95, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 466 \n",
      "\n",
      "Inputs: torch.Size([13, 80, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 497 \n",
      "\n",
      "Inputs: torch.Size([13, 75, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 522 \n",
      "\n",
      "Inputs: torch.Size([13, 81, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 551 \n",
      "\n",
      "Inputs: torch.Size([13, 79, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 582 \n",
      "\n",
      "Inputs: torch.Size([13, 70, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 613 \n",
      "\n",
      "Inputs: torch.Size([13, 89, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 640 \n",
      "\n",
      "Inputs: torch.Size([13, 66, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 667 \n",
      "\n",
      "Inputs: torch.Size([13, 140, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 690 \n",
      "\n",
      "Inputs: torch.Size([13, 56, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 723 \n",
      "\n",
      "Inputs: torch.Size([13, 107, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 750 \n",
      "\n",
      "Inputs: torch.Size([13, 122, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 783 \n",
      "\n",
      "Inputs: torch.Size([13, 107, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 816 \n",
      "\n",
      "Inputs: torch.Size([13, 93, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 849 \n",
      "\n",
      "Inputs: torch.Size([13, 86, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 876 \n",
      "\n",
      "Inputs: torch.Size([13, 89, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 907 \n",
      "\n",
      "Inputs: torch.Size([13, 83, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 934 \n",
      "\n",
      "Inputs: torch.Size([13, 135, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 963 \n",
      "\n",
      "Inputs: torch.Size([13, 146, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 992 \n",
      "\n",
      "Inputs: torch.Size([13, 117, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1011 \n",
      "\n",
      "Inputs: torch.Size([13, 77, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1042 \n",
      "\n",
      "Inputs: torch.Size([13, 90, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1075 \n",
      "\n",
      "Inputs: torch.Size([13, 98, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1108 \n",
      "\n",
      "Inputs: torch.Size([13, 83, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1141 \n",
      "\n",
      "Inputs: torch.Size([13, 86, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1170 \n",
      "\n",
      "Inputs: torch.Size([13, 86, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1199 \n",
      "\n",
      "Inputs: torch.Size([13, 99, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1230 \n",
      "\n",
      "Inputs: torch.Size([13, 89, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1261 \n",
      "\n",
      "Inputs: torch.Size([13, 88, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1296 \n",
      "\n",
      "Inputs: torch.Size([13, 101, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1323 \n",
      "\n",
      "Inputs: torch.Size([13, 113, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1352 \n",
      "\n",
      "Inputs: torch.Size([13, 77, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1379 \n",
      "\n",
      "Inputs: torch.Size([13, 74, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1414 \n",
      "\n",
      "Inputs: torch.Size([13, 73, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1443 \n",
      "\n",
      "Inputs: torch.Size([13, 73, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1474 \n",
      "\n",
      "Inputs: torch.Size([13, 95, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1505 \n",
      "\n",
      "Inputs: torch.Size([13, 85, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1532 \n",
      "\n",
      "Inputs: torch.Size([13, 82, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1569 \n",
      "\n",
      "Inputs: torch.Size([13, 78, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1596 \n",
      "\n",
      "Inputs: torch.Size([13, 108, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1625 \n",
      "\n",
      "Inputs: torch.Size([13, 91, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1658 \n",
      "\n",
      "Inputs: torch.Size([13, 80, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1683 \n",
      "\n",
      "Inputs: torch.Size([13, 97, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1710 \n",
      "\n",
      "Inputs: torch.Size([13, 99, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1735 \n",
      "\n",
      "Inputs: torch.Size([13, 76, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1764 \n",
      "\n",
      "Inputs: torch.Size([13, 147, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1787 \n",
      "\n",
      "Inputs: torch.Size([13, 114, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1818 \n",
      "\n",
      "Inputs: torch.Size([13, 112, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1845 \n",
      "\n",
      "Inputs: torch.Size([13, 119, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1872 \n",
      "\n",
      "Inputs: torch.Size([13, 92, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1899 \n",
      "\n",
      "Inputs: torch.Size([13, 101, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1930 \n",
      "\n",
      "Inputs: torch.Size([13, 79, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1959 \n",
      "\n",
      "Inputs: torch.Size([13, 71, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 1982 \n",
      "\n",
      "Inputs: torch.Size([13, 116, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2015 \n",
      "\n",
      "Inputs: torch.Size([13, 115, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2038 \n",
      "\n",
      "Inputs: torch.Size([13, 86, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2069 \n",
      "\n",
      "Inputs: torch.Size([13, 89, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2096 \n",
      "\n",
      "Inputs: torch.Size([13, 88, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2129 \n",
      "\n",
      "Inputs: torch.Size([13, 95, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2160 \n",
      "\n",
      "Inputs: torch.Size([13, 83, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2189 \n",
      "\n",
      "Inputs: torch.Size([13, 96, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2216 \n",
      "\n",
      "Inputs: torch.Size([13, 151, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2247 \n",
      "\n",
      "Inputs: torch.Size([13, 123, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2270 \n",
      "\n",
      "Inputs: torch.Size([13, 71, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2301 \n",
      "\n",
      "Inputs: torch.Size([13, 93, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2332 \n",
      "\n",
      "Inputs: torch.Size([13, 68, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2351 \n",
      "\n",
      "Inputs: torch.Size([13, 102, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2382 \n",
      "\n",
      "Inputs: torch.Size([13, 129, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2415 \n",
      "\n",
      "Inputs: torch.Size([13, 68, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2438 \n",
      "\n",
      "Inputs: torch.Size([13, 89, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2465 \n",
      "\n",
      "Inputs: torch.Size([13, 83, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2492 \n",
      "\n",
      "Inputs: torch.Size([13, 116, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2523 \n",
      "\n",
      "Inputs: torch.Size([13, 84, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2552 \n",
      "\n",
      "Inputs: torch.Size([13, 70, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2573 \n",
      "\n",
      "Inputs: torch.Size([13, 75, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2598 \n",
      "\n",
      "Inputs: torch.Size([13, 97, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2625 \n",
      "\n",
      "Inputs: torch.Size([13, 82, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2656 \n",
      "\n",
      "Inputs: torch.Size([13, 55, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2681 \n",
      "\n",
      "Inputs: torch.Size([13, 95, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2708 \n",
      "\n",
      "Inputs: torch.Size([13, 104, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2735 \n",
      "\n",
      "Inputs: torch.Size([13, 101, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2762 \n",
      "\n",
      "Inputs: torch.Size([13, 97, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2787 \n",
      "\n",
      "Inputs: torch.Size([13, 131, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2822 \n",
      "\n",
      "Inputs: torch.Size([13, 105, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2851 \n",
      "\n",
      "Inputs: torch.Size([13, 85, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2874 \n",
      "\n",
      "Inputs: torch.Size([13, 74, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2905 \n",
      "\n",
      "Inputs: torch.Size([13, 91, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2940 \n",
      "\n",
      "Inputs: torch.Size([13, 96, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2969 \n",
      "\n",
      "Inputs: torch.Size([13, 83, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 2994 \n",
      "\n",
      "Inputs: torch.Size([13, 98, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3021 \n",
      "\n",
      "Inputs: torch.Size([13, 120, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3054 \n",
      "\n",
      "Inputs: torch.Size([13, 106, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3085 \n",
      "\n",
      "Inputs: torch.Size([13, 94, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3116 \n",
      "\n",
      "Inputs: torch.Size([13, 105, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3143 \n",
      "\n",
      "Inputs: torch.Size([13, 90, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3174 \n",
      "\n",
      "Inputs: torch.Size([13, 91, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3203 \n",
      "\n",
      "Inputs: torch.Size([13, 119, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3238 \n",
      "\n",
      "Inputs: torch.Size([13, 102, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3263 \n",
      "\n",
      "Inputs: torch.Size([13, 105, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3298 \n",
      "\n",
      "Inputs: torch.Size([13, 87, 5])  Labels: torch.Size([13, 5])\n",
      "Outputs: torch.Size([13, 5]) Correct: 3329 \n",
      "\n",
      "Inputs: torch.Size([11, 70, 5])  Labels: torch.Size([11, 5])\n",
      "Outputs: torch.Size([11, 5]) Correct: 3354 \n",
      "\n",
      "Accuracy on test set: 44.54%\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Evaluation -------------------------------------------------------------------\n",
    "\n",
    "[batch size][sequence length][input size/number of features]\n",
    "'''\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = []\n",
    "    total = []\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.round(torch.sigmoid(outputs))  # converting logits to probabilities\n",
    "        correct.append((predicted == labels).sum().item())\n",
    "        total_count += labels.size(0) * labels.size(1)  # Total number of labels\n",
    "        correct_count += (predicted == labels).sum().item()\n",
    "        print(f'Inputs: {inputs.shape}  Labels: {labels.shape}')\n",
    "        print(f'Outputs: {outputs.shape} Correct: {correct_count} \\n')\n",
    "\n",
    "    print(f'Accuracy on test set: {(correct_count/total_count) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([ 3.4704e-01,  1.1869e-01,  1.1574e-01,  8.2077e-02,  5.5813e-02,\n",
       "          3.1093e-02,  2.2187e-02,  1.9635e-02,  1.7024e-02,  1.6102e-02,\n",
       "          1.5947e-02,  1.3207e-02,  1.2627e-02,  1.1193e-02,  1.0204e-02,\n",
       "          1.0054e-02,  9.0737e-03,  8.0491e-03,  7.7192e-03,  7.5888e-03,\n",
       "          6.7408e-03,  6.4573e-03,  5.2918e-03,  5.1927e-03,  4.9273e-03,\n",
       "          4.8966e-03,  4.1454e-03,  3.7508e-03,  3.5925e-03,  3.3263e-03,\n",
       "          3.1473e-03,  2.8536e-03,  2.6036e-03,  2.4031e-03,  2.3430e-03,\n",
       "          2.0198e-03,  1.6181e-03,  1.5652e-03,  1.3808e-03,  1.0791e-03,\n",
       "          9.4074e-04,  7.1847e-04,  4.7826e-04,  4.7442e-04,  1.1651e-04,\n",
       "          0.0000e+00, -1.0468e-02, -1.6900e-02, -1.0503e-02,  8.4449e-03,\n",
       "         -3.5364e-03,  6.7515e-14, -1.9937e-03,  8.9245e-03, -2.0778e-02,\n",
       "         -3.6403e-03,  6.7177e-03, -1.4146e-04, -3.9678e-02,  4.7722e-03,\n",
       "         -5.3258e-02,  2.9307e-02,  1.4913e-03,  1.7846e-02,  3.3074e-02,\n",
       "          2.1003e-02,  1.4344e-02, -4.4059e-02, -1.0141e-02, -4.9551e-02,\n",
       "         -4.0477e-02, -1.6452e-02, -1.0635e-02, -9.0806e-02, -5.0850e-02,\n",
       "          2.1413e-02,  3.7008e-02, -9.1167e-02, -2.3489e-01, -6.9516e-02,\n",
       "          1.3328e-01, -6.1899e-02, -2.0951e-02, -3.8437e-02, -1.9280e-01,\n",
       "          2.7853e-02, -1.0439e-01, -2.7128e-02, -7.7099e-02,  7.3177e-02,\n",
       "          0.0000e+00,  7.6020e-03,  1.6648e-02,  4.0990e-03, -6.4844e-03,\n",
       "          3.5652e-02, -2.3148e-01,  2.9208e-03, -2.3820e-01,  2.9480e-03,\n",
       "         -2.3403e-01, -2.2255e-01,  1.2753e-02,  1.4942e-02,  1.1827e-02,\n",
       "          2.7854e-02, -2.5243e-01, -2.1542e-01, -2.4491e-01, -2.1724e-01,\n",
       "         -2.1682e-01, -2.0871e-01, -2.3612e-01, -1.1011e-01,  4.7511e-02,\n",
       "          4.2671e-02, -1.9809e-02, -5.8842e-02, -1.9950e-01, -1.3326e-02,\n",
       "          1.0033e-01, -1.8498e-01, -1.7393e-01,  8.2898e-02, -9.8950e-02,\n",
       "         -1.3496e-01, -2.1052e-01, -2.0307e-01, -2.1934e-01, -1.5748e-01,\n",
       "         -2.4109e-01,  1.5288e-01,  5.8553e-02,  1.4420e-01, -5.7055e-02,\n",
       "          3.4617e-01,  1.1736e-01,  1.1376e-01,  8.1192e-02,  5.6076e-02,\n",
       "          3.0781e-02,  2.2862e-02,  1.9549e-02,  1.7679e-02,  1.5811e-02,\n",
       "          1.6393e-02,  1.3661e-02,  1.2572e-02,  1.0823e-02,  1.0197e-02,\n",
       "          9.6098e-03,  9.5913e-03,  8.2853e-03,  8.0787e-03,  8.0046e-03,\n",
       "          7.0444e-03,  6.7055e-03,  5.2786e-03,  5.2214e-03,  4.7096e-03,\n",
       "          4.7148e-03,  4.0963e-03,  3.7437e-03,  3.4464e-03,  3.2027e-03,\n",
       "          3.1454e-03,  3.0065e-03,  2.4886e-03,  2.0215e-03,  2.2518e-03,\n",
       "          2.2796e-03,  1.5899e-03,  1.5837e-03,  1.3799e-03,  9.5955e-04,\n",
       "          9.9551e-04,  6.5756e-04,  4.6389e-04,  4.3902e-04,  1.2387e-04,\n",
       "          2.6570e-02,  3.4597e-02,  4.4962e-02,  3.1178e-02,  2.3233e-02,\n",
       "          6.1971e-02,  2.0526e-01,  2.9286e-02,  2.1235e-01,  3.3907e-02,\n",
       "          2.0777e-01,  1.9658e-01,  3.9228e-02,  5.4773e-02,  3.9065e-02,\n",
       "          7.3454e-02,  2.2869e-01,  1.8923e-01,  2.1978e-01,  1.9457e-01,\n",
       "          1.9220e-01,  1.8336e-01,  2.1359e-01,  8.4040e-02,  8.6941e-02,\n",
       "          7.8207e-02,  1.4357e-02,  3.3264e-02,  1.9368e-01,  4.8947e-02,\n",
       "          1.2910e-01,  1.6389e-01,  1.7145e-01,  2.5592e-01,  9.8003e-02,\n",
       "          1.7501e-01,  1.9308e-01,  1.7759e-01,  1.9608e-01,  2.2970e-01,\n",
       "          2.1724e-01,  2.0577e-01,  8.8065e-02,  1.8579e-01,  8.2777e-02]), batch_sizes=tensor([45, 45, 45, 45, 45]), sorted_indices=tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44]), unsorted_indices=tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44])),\n",
       " array([0, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- STEP 1: establishing training features (x) and training targets (y) data -----------------------\n",
    "# Step 1: Initialize ParticleDataset\n",
    "particle_dataset = ParticleDataset(shuffle(data))\n",
    "# particle_dataset[0] means it returns a single element with its 'x' and 'y' values\n",
    "\n",
    "# Shuffle the indices to split the data randomly\n",
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Define the sizes for train, validation, and test sets\n",
    "train_size = int(0.6 * len(data))\n",
    "val_size = int(0.2 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "# Split the indices\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size+val_size]\n",
    "test_indices = indices[train_size+val_size:]\n",
    "\n",
    "# Define datasets and data loaders for each set\n",
    "train_dataset = Subset(particle_dataset, train_indices)\n",
    "val_dataset = Subset(particle_dataset, val_indices)\n",
    "test_dataset = Subset(particle_dataset, test_indices)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "# # ---- STEP 3: sending to GPU  --------------------------------------------------------------\n",
    "# print(\"\\n --Sending to GPU--\")\n",
    "\n",
    "# with warnings.catch_warnings(): # booo warnings\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#     trfeat = torch.tensor(torch.from_numpy(trfeat), dtype=torch.float32).to(DEVICE)\n",
    "#     trtarget = torch.tensor(torch.from_numpy(trtarget), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "#     vafeat = torch.tensor(torch.from_numpy(vafeat), dtype=torch.float32).to(DEVICE)\n",
    "#     vatarget = torch.tensor(torch.from_numpy(vatarget), dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "#     tefeat = torch.tensor(torch.from_numpy(tefeat), dtype=torch.float32).to(DEVICE)\n",
    "#     tetarget = torch.tensor(torch.from_numpy(tetarget), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# # Determine lengths of sequences for packed sequences\n",
    "# trlengths = torch.tensor([len(seq) for seq in trfeat]).to(DEVICE)\n",
    "# valengths = torch.tensor([len(seq) for seq in vafeat]).to(DEVICE)\n",
    "# telengths = torch.tensor([len(seq) for seq in tefeat]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class ParticleClassifierLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(ParticleClassifierLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        packed_input = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (h_n, c_n) = self.lstm(packed_input)\n",
    "        output, _ = rnn_utils.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        idx = (lengths - 1).view(-1, 1).expand(len(lengths), output.size(2)).unsqueeze(1).to(DEVICE)\n",
    "        last_output = output.gather(1, idx).squeeze(1)\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = ParticleClassifierLSTM(\n",
    "    input_dim = 5, \n",
    "    hidden_dim = 100, \n",
    "    num_layers = 2, \n",
    "    num_classes = 5\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'lengths' argument should be a 1D CPU int64 tensor, but got 2D cpu Long tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Unpack the packed sequence\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     inputs, lengths \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE), targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\ebaca\\anaconda3\\envs\\Phys417\\Lib\\site-packages\\torch\\nn\\utils\\rnn.py:333\u001b[0m, in \u001b[0;36mpad_packed_sequence\u001b[1;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected total_length to be at least the length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the longest sequence in input, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    330\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and max sequence length being \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_seq_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m                          )\n\u001b[0;32m    332\u001b[0m     max_seq_length \u001b[38;5;241m=\u001b[39m total_length\n\u001b[1;32m--> 333\u001b[0m padded_output, lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m unsorted_indices \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39munsorted_indices\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 2D cpu Long tensor"
     ]
    }
   ],
   "source": [
    "# Assuming you have defined the model, loss function, optimizer, and other necessary components\n",
    "num_epochs = 50\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # Unpack the packed sequence\n",
    "        inputs, lengths = nn.utils.rnn.pad_packed_sequence(inputs, batch_first=True)\n",
    "        \n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, lengths)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for inputs, targets in val_loader:\n",
    "            # Unpack the packed sequence\n",
    "            inputs, lengths = nn.utils.rnn.pad_packed_sequence(inputs, batch_first=True)\n",
    "            \n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs, lengths)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Training loop\n",
    "\n",
    "def train(model, loss_fn, optimizer, epochs, trfeat, trtarget, vafeat, vatarget, trlengths, valengths, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(trfeat), batch_size):\n",
    "            x_batch = trfeat[i:i+batch_size]\n",
    "            y_batch = trtarget[i:i+batch_size]\n",
    "            lengths_batch = trlengths[i:i+batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch, lengths_batch)\n",
    "            loss = loss_fn(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, loss_fn, vafeat, vatarget, valengths)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
    "\n",
    "def evaluate(model, loss_fn, vafeat, vatarget, valengths):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(vafeat, valengths)\n",
    "        loss = loss_fn(output, vatarget)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        accuracy = (preds == vatarget).float().mean()\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, loss_fn, optimizer, epochs, trfeat, trtarget, vafeat, vatarget, trlengths, valengths, batch_size)\n",
    "evaluate(model, loss_fn, vafeat, vatarget, valengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = classifier(tefeat)\n",
    "_ignore_, predicted = torch.max(test_outputs, 1)\n",
    "correct = (predicted == tetarget).float()\n",
    "accuracy = correct.mean().item()\n",
    "# print(f'Test Accuracy: {accuracy*100:.3f}%')\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure(figsize = (12, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trlosses, linewidth = 3)\n",
    "# plt.plot(runner.losses, linewidth = 3)\n",
    "plt.ylabel(\"Losses in Training\")\n",
    "plt.annotate(f'Learning Rate: {learning_rate} \\nBatch Size: {batch_size} \\nLowest Loss: {min(trlosses):.3f}', \n",
    "             xy=(0.95, 0.85), xycoords='axes fraction', va='top', ha='right')\n",
    "sns.despine()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(valosses, linewidth = 3, color = 'gold')\n",
    "# plt.plot(runner.accuracies, linewidth = 3, color = 'gold')\n",
    "plt.ylabel(\"Training Accuracy (Validation)\")\n",
    "plt.annotate(f'Accuracy: {accuracy*100:.3f}%', xy=(0.95, 0.20), xycoords='axes fraction', va='top', ha='right')\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phys417",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
