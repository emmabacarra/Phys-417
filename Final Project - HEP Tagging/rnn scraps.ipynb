{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = shuffle([f for f in os.listdir('../../PHYS417_Project/data')])\n",
    "\n",
    "# test_index = 0\n",
    "# data = []\n",
    "\n",
    "# for i, f in enumerate(files[:100]):\n",
    "#     with np.load('../../PHYS417_Project/data/' + f) as data_load:\n",
    "#         x_load = data_load['x']\n",
    "#         y_load = data_load['y']\n",
    "#         data.append([x_load, y_load])\n",
    "\n",
    "#         if i == test_index:\n",
    "#             print(x_load.shape, y_load, '\\n')\n",
    "\n",
    "# data = np.array(data, dtype=object)\n",
    "\n",
    "# '''\n",
    "# the dataset then contains these dimensions:\n",
    "# data[event index][event information][event constituents]\n",
    "\n",
    "# event index: \n",
    "# data[i] = [event1, event2, ..., eventn]\n",
    "# - index for a specific event in a set number of sampled events\n",
    "# - number of samples stays the same throughout a training session\n",
    "\n",
    "# event information:\n",
    "# data[i][0] = [[constituent1], [constituent2], ..., [constituentn]]\n",
    "# data[i][1] = [one-hot encoded jet tag for 5 categories]\n",
    "# - 0 for a variable number of constituents and their 5 properties (data['x'] of one event file)\n",
    "# - 1 for the jet tag (represented as a one-hot encoded vector) (data['y'] of one event file)\n",
    "# - always either 0 or 1, doesn't change ever\n",
    "\n",
    "# event constituents: \n",
    "# data[i][0][constituentn] = [momentum, eta, phi, energy, distance]\n",
    "# - varying number n for each event[i][0][n]\n",
    "# - each represents a row of the nx5 matrix in event[i][0]\n",
    "\n",
    "# '''\n",
    "\n",
    "# class ParticleDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.data[idx]\n",
    "        \n",
    "#         # Convert x to a list of tensors\n",
    "#         x_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in x]\n",
    "        \n",
    "#         # Pack the sequence of tensors\n",
    "#         packed_x = pack_sequence(x_tensors, enforce_sorted=False)\n",
    "        \n",
    "#         return packed_x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Final shape of data_array: {data.shape}\", f\"\\nShape X (features) {data[:, 0].shape}\", f\"\\nShape Y (targets) {data[:, 1].shape}\\n\")\n",
    "\n",
    "# print(data[test_index, 0].shape, data[test_index, 1]) # [data element index][0 for data_load['x'], 1 for data_load['y']][constituent index]\n",
    "\n",
    "# # class ParticleDataset(Dataset):\n",
    "# #     def __init__(self, data):\n",
    "# #         self.data = data\n",
    "        \n",
    "# #     def __len__(self):\n",
    "# #         return len(self.data)\n",
    "    \n",
    "# #     def __getitem__(self, idx):\n",
    "# #         # Return a tuple containing features (x) and targets (y)\n",
    "# #         return self.data[idx][0], self.data[idx][1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
